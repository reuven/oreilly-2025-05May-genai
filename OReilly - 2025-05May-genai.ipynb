{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "\n",
    "1. What are LLMs and modern chatbots?\n",
    "2. How can we use them?\n",
    "3. Pair programming -- without and with ChatGPT\n",
    "4. Pair programming with Claude\n",
    "    - Rubber-duck programming with LLMs\n",
    "    - Enthusiastic intern\n",
    "    - Interview technique for learning more\n",
    "5. Developing tests with `pytest`, along with a chatbot's help\n",
    "6. Using a chatbot in debugging\n",
    "7. Using a chatbot for researching -- the \"reverse Socratic\" method\n",
    "8. Copilot inside of your IDE -- good and bad\n",
    "9. Where do we go next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to ChatGPT\n",
    "\n",
    "ChatGPT was released 2.5 years ago at this point. It's a very sophsticated LLM (large-language model). The idea is:\n",
    "\n",
    "- They have \"trained\" ChatGPT on a huge number of documents on the Internet (and not on the Internet)\n",
    "- You can ask it a question, and it'll answer you, word by word, using a fancy kind of autocomplete\n",
    "\n",
    "If you ask a chatbot to answer a question, it will more likely than not be able to answer, both because it has a lot of information that it has assimilated, and because the sheer number of documents it has incorporated into its training makes it likely that the \"average sentence\" on a subject that it creates will be reasonable.\n",
    "\n",
    "Not only can ChatGPT give us text, but it can also give us *code*, and it does a decent job of creating a lot of code.\n",
    "\n",
    "Mistake #1 that I believe people make with LLMs is: Having it write code for them.\n",
    "\n",
    "Part 2 of this belief is: If you really want to have an LLM write code, then you will need the expertise to review it thoroughly and make sure that it's reasonable. If you would be willing to explain and defend the code in a code-review session at your company, then yes, let the LLM write code.\n",
    "\n",
    "People are talking about \"vibe-coding\" in the last few months, where even if you don't have experience coding, you can ask the LLM to code for you, and it'll create applications. In many *many* cases, these applications have security problems, major bugs, etc. \n",
    "\n",
    "People would say, \"The programming language of the future is English,\" because if everyone has access to ChatGPT, and everyone can describe what code they want, then they will get great code without needing programmers.\n",
    "\n",
    "Copmanies are now slowing down their hiring of new coders, and relying on experienced coders + LLMs to write their code. BUT what will happen when the seniors retire? How will the juniors get their experience? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If not coding, then what?\n",
    "\n",
    "I would say that LLMs are a huge benefit/boon to programmers, but not for writing code. One of the best ways to use them is as a sounding board, to get a response to what you're thinking/planning, or even what you have already written.\n",
    "\n",
    "I think it's totally OK (even a good thing) to tell an LLM what you plan to do before you start coding. I intend to solve this problem in the following way (using pseudo-code), and ask the LLM -- what does it think? (Also, tell it not to write code.)\n",
    "\n",
    "- It might well over-flatter you.\n",
    "\n",
    "Argue with it! The best thing you can do for your sanity, and also for the quality of your work, and also to ensure that the LLM isn't hallucinating, is to argue -- ask it lots of questions. Is that really true? Why is that the case? Wouldn't it be better to do X instead of Y? What are the trade-offs between X and Y?\n",
    "\n",
    "One metaphor that I heard is: A chatbot is a very enthusisastic intern. \n",
    "\n",
    "### Once you've finished coding...\n",
    "\n",
    "Run your code through the LLM, and ask it, \"What do you think?\"\n",
    "\n",
    "You'll get feedback quickly and well, and you have to have the sophistication/experience to know what to listen to, what to throw out, and what to ask more questions about.\n",
    "\n",
    "Because LLMs are trained on code/text that's out in the wild, and because Python has a long history and is very popular, it's easy for a chatbot to write Python. If you were to ask it to write in another language, then it would have less history and information, and would write worse code.\n",
    "\n",
    "A chatbot gives you the average text from the Internet on a subject... \n",
    "\n",
    "If you use English, you will get far better results than in other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair programming\n",
    "\n",
    "Pair programming isn't new -- the idea is that two people work on the same computer. Some people say you should *always* pair. In my courses, if two people are working on a single computer, they almost always finish the exercise faster, they finish it more correctly, and they remember what they did better -- in other words, it's a better learning experience.\n",
    "\n",
    "Pairing has issues -- the other person needs to be available, you need to have compatible personalities, and they need to understand something of what you're doing.\n",
    "\n",
    "Pairing with an LLM can be very convenient, especially because a big benefit of pairing is not the other person! A big benefit is that you're talking to the other person, describing your approach, code, and plan, and just having to phrase and express those ideas forces you to crystallize your thinking, and thus write better code.\n",
    "\n",
    "1. Present your strategy to the LLM\n",
    "2. As you code, or as you're going to write, ask the LLM what it thinks about each line, or function, or section of code. You might want to say, \"Don't rewrite the code\" in your prompt, to avoid that sort of thing.\n",
    "3. Don't be afraid to push back and argue! Just because it's an LLM doesn't mean that it's the best coder in the world!\n",
    "\n",
    "With enough back-and-forth, you'll be more confident (and knowledgeable) about your code, and you will have avoided truly big, stupid errors.\n",
    "\n",
    "You can also pair *after* the coding phase. Once you've finished coding, give the code to the LLM, and have it review things.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Great book: \"Weapons of Math Destruction\" from Cathy O'Neil\n",
    "- Tay on Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Pig Latin translator\n",
    "\n",
    "1. Write a function, `pl_word`, that takes a single word (all lowercase, no punctuation) and returns a string in which the word is translated into Pig Latin.\n",
    "2. Write a function, `pl_sentence`, that does the same thing for a sentence (all lowercase, no punctuation, but spaces between words).\n",
    "\n",
    "Rules for Pig Latin (children's \"secret\" language):\n",
    "- If a word starts with a vowel (a, e, i, o, u) then return the word + `way`\n",
    "- Otherwise, move the first letter to the end, and add `ay`\n",
    "\n",
    "Examples:\n",
    "\n",
    "- `computer` -> `omputercay`\n",
    "- `apple` -> `appleway`\n",
    "- `papaya` -> `apayapay`\n",
    "\n",
    "1. Get feedback on your strategy from an LLM\n",
    "2. Get feedback on your code, too.\n",
    "3. If your functions work together, then get feedback on how you did that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up\n",
    "\n",
    "1. Claude vs. ChatGPT\n",
    "2. Adding tests to our code, and where a chatbot can help\n",
    "3. Interview technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude vs. ChatGPT\n",
    "\n",
    "ChatGPT was created by OpenAI, which was started as a non-profit lab to help everyone with AI, and is now making the transition to being a for-profit company. They especially wanted to make AI safe for people to use. Along the way, some of the original people at OpenAI left, saying that they weren't as dedicated to safety as they could be.\n",
    "\n",
    "Anthropic, the company founded by these people who left OpenAI, are adamant that they will only release safe LLMs. Claude is their LLM, and it works very similarly to ChatGPT, except that it has more of a filter.\n",
    "\n",
    "It has become something of a darling in the coding community. It had \"projects\" before ChatGPT did, which was nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Testing is an important part of any reasonable , and certainly commercial, software project. Writing tests can be tedious and frustrating.\n",
    "\n",
    "This is one place where I'm sorta kinda willing to let a chatbot take the lead, or at least write a number of the tests.\n",
    "\n",
    "Part of the reason I'm willing to outsource the tests (to some degree) to an LLM is that we can use `coverage` to check how much of our code is covered.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Write (and check) some tests\n",
    "\n",
    "1. Have the chatbot write tests for your Pig Latin translation program.\n",
    "2. Once it has finished writing tests, run the tests. Do they all pass? If not, can you identify the issue? Can the chatbot?\n",
    "3. When it's done writing tests, have it criticize/enhance the tests. What do you think?\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interview technique\n",
    "\n",
    "Especially if you are learning Python (or any other language), I love to use the interview technique to improve my understanding. The idea is that we start with code that *does* work, such as after an exercise has been solved.\n",
    "\n",
    "You give the LLM your code, and then ask it to interview you about the code, asking questions to make sure you really understand it. You should specify how deep you want to go, and what your level of experience is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up\n",
    "\n",
    "1. Using LLMs in debugging\n",
    "2. The reverse Socratic method\n",
    "3. Using Copilot in your IDE\n",
    "4. What next? Where do we go from here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs and debugging\n",
    "\n",
    "We used to: Take an error message, and paste it into a search engine's field. On the assumption that someone, somewhere has already encountered that error, we'll (potentially) find the solution.\n",
    "\n",
    "Nowadays, we can do that with an LLM. Moreover, we can copy a *LOT* of the error code into the LLM, and it'll often be able to help us out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Reuven\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'stripp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m name = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEnter your name: \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstripp\u001b[49m()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mHello, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m!\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'stripp'"
     ]
    }
   ],
   "source": [
    "name = input('Enter your name: ').stripp()\n",
    "\n",
    "print(f'Hello, {name}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, 30, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_1(x=[]):\n",
    "    x.append(1)\n",
    "    return x\n",
    "\n",
    "mylist = [10, 20, 30]\n",
    "add_1(mylist)\n",
    "mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def add_1(x=[]):\n",
    "    x.append(1)\n",
    "    return x\n",
    "\n",
    "for i in range(5):\n",
    "    print(add_1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
